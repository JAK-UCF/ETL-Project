{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ELT Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding Data:\n",
    "\n",
    "DATA SOURCE: https://www.kaggle.com/datasnaek/youtube-new/data <br/>\n",
    "Utilizing: <br/>\n",
    "3 csv files with Video Information (Canada, US, and Britain) <br/>\n",
    "3 json files with Category Assignment (Canada, US, and Britain) <br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleanup & Analysis\n",
    "\n",
    "Plan and document the following:\n",
    "* The sources of data that you will extract from.\n",
    "* The type of transformation needed for this data (cleaning, joining, filtering, aggregating, etc).\n",
    "* The type of final production database to load the data into (relational or non-relational).\n",
    "* The final tables or collections that will be used in the production database.\n",
    "\n",
    "You will be required to submit a final technical report with the above information and steps required to reproduce your ETL process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Report:\n",
    "\n",
    "Submit a Final Report that describes the following:\n",
    "* Extract: your original data sources and how the data was formatted (CSV, JSON, pgAdmin 4, etc).\n",
    "* Transform: what data cleaning or transformation was required.\n",
    "* Load: the final database, tables/collections, and why this was chosen.\n",
    "\n",
    "Please upload the report to Github and submit a link to Bootcampspot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "import requests\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "# pd.options.display.max_rows = 3000\n",
    "\n",
    "from pandas.io.json import json_normalize\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXTRACT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading in Canada csv video info\n",
    "ca_file = os.path.join(\"data\", \"CAvideos.csv\")\n",
    "CA_df = pd.read_csv(ca_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading in Canada json category keys\n",
    "json_CA = os.path.join(\"data\", \"CA_category_id.json\")\n",
    "category_CA_df = pd.read_json(json_CA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading in Great Britain csv video info\n",
    "gb_file = os.path.join(\"data\", \"GBvideos.csv\")\n",
    "GB_df = pd.read_csv(gb_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading in Great Britain json category keys\n",
    "json_GB = os.path.join(\"data\", \"GB_category_id.json\")\n",
    "category_GB_df = pd.read_json(json_GB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading in United States csv video info\n",
    "us_file = os.path.join(\"data\", \"USvideos.csv\")\n",
    "US_df = pd.read_csv(us_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading in United States json category keys\n",
    "json_US = os.path.join(\"data\", \"US_category_id.json\")\n",
    "category_US_df = pd.read_json(json_US)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRANSFORM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean up Canada category df with json_normalize (pulls dictionary items into their own column)\n",
    "#drop static YouTube info not needed for video database, rename column and cast category_id to number for merge\n",
    "CA_category_df = json_normalize(category_CA_df['items'])\n",
    "CA_category_df.drop(['etag', 'kind', 'snippet.assignable', 'snippet.channelId'], axis=1, inplace=True)\n",
    "CA_category_df.rename(columns={'id': 'category_id', 'snippet.title': 'category_name'}, inplace=True)\n",
    "CA_categories = CA_category_df.astype({'category_id': 'int64'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding a column to Canada video df to define which country info came from after upcoming concat\n",
    "CA_df.insert(1,\"country\", \"CA\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge category_names into CA_df\n",
    "CAfull_df = CA_df.merge(CA_categories, how='left', on=\"category_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CAfull_df.count()     # video_id: 40881 - category_name: 40807  [NaN: 74]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean up Great Britain category df with json_normalize (pulls dictionary items into their own column)\n",
    "#drop static YouTube info not needed for video database, rename column and cast category_id to number for merge\n",
    "GB_category_df = json_normalize(category_GB_df['items'])\n",
    "GB_category_df.drop(['etag', 'kind', 'snippet.assignable', 'snippet.channelId'], axis=1, inplace=True)\n",
    "GB_category_df.rename(columns={'id': 'category_id', 'snippet.title': 'category_name'}, inplace=True)\n",
    "GB_categories = GB_category_df.astype({'category_id': 'int64'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding a column to Great Britain video df to define which country info came from after upcoming concat\n",
    "GB_df.insert(1,\"country\", \"GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge category_names into GB_df\n",
    "GBfull_df = GB_df.merge(GB_categories, how='left', on=\"category_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GBfull_df.count()     # video_id: 38916 - category_name: 38826  [NaN: 90]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean up United States category df with json_normalize (pulls dictionary items into their own column)\n",
    "#drop static YouTube info not needed for video database, rename column and cast category_id to number for merge\n",
    "US_category_df = json_normalize(category_US_df['items'])\n",
    "US_category_df.drop(['etag', 'kind', 'snippet.assignable', 'snippet.channelId'], axis=1, inplace=True)\n",
    "US_category_df.rename(columns={'id': 'category_id', 'snippet.title': 'category_name'}, inplace=True)\n",
    "US_categories = US_category_df.astype({'category_id': 'int64'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding a column to United States video df to define which country info came from after upcoming concat\n",
    "US_df.insert(1,\"country\", \"US\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge category_names into US_df\n",
    "USfull_df = US_df.merge(US_categories, how='left', on=\"category_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# USfull_df.count()     # video_id: 40949 - category_name: 40949  [NaN: 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pull only the most recent stats per video (for each CA, GB, and US df)\n",
    "#1> add MaxDate col: take most recent trending_date for each video_id and assign every copy of that video_id\n",
    "#2> filter the df to only the videos where trending_date and MaxDate are the same\n",
    "\n",
    "CAfull_df['MaxDate'] = CAfull_df.groupby('video_id').trending_date.transform('max') # CA_df COUNT: 40881(max)\n",
    "final_CA_df = CAfull_df[CAfull_df['MaxDate'] == CAfull_df['trending_date']] # final_CA_df COUNT: 24427(max)\n",
    "\n",
    "GBfull_df['MaxDate'] = GBfull_df.groupby('video_id').trending_date.transform('max') # GB_df COUNT: 38916(max)\n",
    "final_GB_df = GBfull_df[GBfull_df['MaxDate'] == GBfull_df['trending_date']] # final_CA_df COUNT: 3300(max)\n",
    "\n",
    "USfull_df['MaxDate'] = USfull_df.groupby('video_id').trending_date.transform('max') # US_df COUNT: 40949(max)\n",
    "final_US_df = USfull_df[USfull_df['MaxDate'] == USfull_df['trending_date']] # final_US_df COUNT: 6354(max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_frame = pd.concat([final_CA_df, final_GB_df, final_US_df], ignore_index=True) # full_frame COUNT: 34081(max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FILL NaN VALUES: 'description' [filling 1116 NaN descriptions]\n",
    "full_frame['description'].fillna(\"No description provided.\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# full_frame.count()     # video_id: 34081 - category_name: 34026  [NaN: 55 (others were dropped in the MaxDate filter)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FILL NaN VALUES: 'category_name'\n",
    "# unsure why none of the json sets contained the category assigner for 'Nonprofits & Activism' (category_id 29 *Google)\n",
    "# specifying this category_id for future use (if category_id != 29, will not fillna...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get index list of all category_id == 29 rows\n",
    "\n",
    "# cat_id_29_idx = full_frame.index[full_frame['category_id'] == 29]\n",
    "# cat_id_29_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test frame based on category_id == 29\n",
    "#run before and after setting np.array as series to replace NaN in category_name with 'Nonprofits...'\n",
    "\n",
    "# validator = full_frame.loc[cat_id_29_idx]\n",
    "# validator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fill NaN 'Nonprofits...' in an array\n",
    "cat_name_full_set = np.where(pd.isnull(full_frame.category_name), \"Nonprofits & Activism\", full_frame.category_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert array to pandas series and overwrite 'category_name' column\n",
    "full_frame['category_name'] = pd.Series(cat_name_full_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert 'publish_time' to datetime format\n",
    "full_frame['publish_time'] = pd.to_datetime(full_frame['publish_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pull just date from full publish_date\n",
    "full_frame['publish_date'] = full_frame['publish_time'].dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop unnecessary columns not using for project\n",
    "full_frame.drop(['thumbnail_link', \n",
    "                 'ratings_disabled', \n",
    "                 'video_error_or_removed', \n",
    "                 'publish_time', \n",
    "                 'MaxDate'] , axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reorganize columns\n",
    "full_frame = full_frame[['video_id',\n",
    "                         'title', \n",
    "                         'channel_title', \n",
    "                         'views', \n",
    "                         'likes', \n",
    "                         'dislikes', \n",
    "                         'comments_disabled', \n",
    "                         'comment_count', \n",
    "                         'description', \n",
    "                         'tags', \n",
    "                         'category_id', \n",
    "                         'category_name', \n",
    "                         'publish_date', \n",
    "                         'trending_date', \n",
    "                         'country']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# full_frame.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
